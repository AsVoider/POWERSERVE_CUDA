stages:
  - check_format
  - setup
  - build
  - deploy
  - test

workflow:
  rules:
    - if: $CI_PIPELINE_SOURCE == 'merge_request_event'
    # 如果branch名称里含ci，就执行
    - if: $CI_COMMIT_BRANCH =~ /ci/


variables:
  GIT_SUBMODULE_STRATEGY: recursive
  IMAGE_NAME: ubuntu:22.04
  CONTAINER_NAME: ndk
  HF_TOKEN: "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"
  HOME: /tmp
  # CI_DEBUG_TRACE: true
  # 如果branch名称里含ci，就把CI_DEBUG_TRACE设置为true




check_formatting:
  stage: check_format
  script:
    - CLANG_FORMAT=/home/gitlab-runner/Downloads/clang-format-18
    - $CLANG_FORMAT --version
    - cd "$CI_PROJECT_DIR"
    - echo "Checking formatting from ${CI_MERGE_REQUEST_DIFF_BASE_SHA}..."
    - format_diff=$(git-clang-format --binary $CLANG_FORMAT ${CI_MERGE_REQUEST_DIFF_BASE_SHA} --diff)
    - echo $format_diff
    - linter_errors=$(echo $format_diff | grep -E --color=never "no modified files to format|clang-format did not modify any files" || true)
    - echo "$linter_errors"
    - if [ -z "$linter_errors" ]; then echo "Detected formatting issues; please fix"; exit 1; else echo "Formatting is correct"; exit 0; fi

setup:
  stage: setup
  # hooks:
  #   pre_get_sources_script:
  #   - sudo rm -rf /home/gitlab-runner/builds/ZxyLxtSdy/
  #   - sudo rm -rf /tmp/ZxyLxtSdy/
  #   - ls -ahl /tmp/${RUNNER_ID}
  # before_script:
  #   - pwd .
  #   - echo "$CI_PROJECT_DIR"
  #   - sudo chmod -R 777 .
  script:
    - pwd
    - sudo podman stop $CONTAINER_NAME || true
    - sudo podman rm $CONTAINER_NAME || true
    # - export https_proxy=http://ipads:ipads123@202.120.40.82:11235
    - git submodule update --init --recursive
    - sudo -E podman run -v $(realpath .):/code -v $(realpath /home/gitlab-runner/Downloads):/data -v $(realpath /opt/qcom/aistack/qairt/2.26.0.240828):/qnn -dit --name ndk ubuntu:22.04
    - sudo podman exec -it $CONTAINER_NAME bash -c "echo -e 'deb http://mirrors.aliyun.com/ubuntu/ jammy main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ jammy-updates main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ jammy-backports main restricted universe multiverse\ndeb http://mirrors.aliyun.com/ubuntu/ jammy-security main restricted universe multiverse' | tee /etc/apt/sources.list"
    - sudo podman exec -it $CONTAINER_NAME bash -c "apt update && apt upgrade -y && apt install -y sudo vim cmake unzip git python-is-python3 python3-pip build-essential"
    # - sudo podman exec -it $CONTAINER_NAME bash -c "pip install -r /code/requirements.txt"
    - sudo podman exec -it $CONTAINER_NAME bash -c "git config --global --add safe.directory /code"
    # - sudo wget https://dl.google.com/android/repository/android-ndk-r27b-linux.zip?hl=zh-cn -O ~/Downloads/android-ndk-r27b-linux.zip
    # - export https_proxy=http://ipads:ipads123@202.120.40.82:11235
    # - sudo podman exec -it $CONTAINER_NAME bash -c "cd /code && git submodule update --init --recursive"

# convert:
#   stage: convert
#   script:
#     - if [ "$REBUILD_ENV" = "true" ]; then
#       sudo podman exec -it $CONTAINER_NAME bash -c "pip install 'huggingface_hub[cli]'";
#       sudo podman exec -it $CONTAINER_NAME bash -c "huggingface-cli login --token $HF_TOKEN";
#       sudo podman exec -it $CONTAINER_NAME bash -c "cd /code && export HF_ENDPOINT=https://hf-mirror.com";
#       sudo podman exec -it $CONTAINER_NAME bash -c "cd /code && huggingface-cli download --cache-dir /data/hf_cache --resume-download meta-llama/Meta-Llama-3.1-8B --exclude original/ --local-dir /data/llama_3.1_8b";
#       sudo podman exec -it $CONTAINER_NAME bash -c "cd /code/tools/convert_hf_to_gguf && python convert_hf_to_gguf.py /data/llama_3.1_8b --outtype f16 --outfile /data/llama_3.1_8b.gguf";
#       fi
# - sudo podman exec -it $CONTAINER_NAME bash -c "cd /code && cmake -DCMAKE_BUILD_TYPE=Release -S . -B build_native"
# - sudo podman exec -it $CONTAINER_NAME bash -c "cd /code && cmake --build build_native --config Release --target llama-quantize"
# - sudo podman exec -it $CONTAINER_NAME bash -c "cd /code && ./build_native/bin/llama-quantize --pure /data/llama_3.1_8b.gguf /data/llama_3.1_8b_q4_0.gguf q4_0"

build:
  stage: build
  script:
    # - sudo podman exec -it $CONTAINER_NAME bash -c "unzip /data/android-ndk-r27b-linux.zip -d /data"
    - sudo podman exec -it $CONTAINER_NAME bash -c "export QNN_SDK_ROOT=/qnn"
    - sudo podman exec -it $CONTAINER_NAME bash -c "echo 'export QNN_SDK_ROOT=/qnn' >> ~/.bashrc"
    - sudo podman exec -it $CONTAINER_NAME bash -c "echo 'export NDK=/data/android-ndk-r27b' >> ~/.bashrc"
    - sudo podman exec -it $CONTAINER_NAME bash -c "source ~/.bashrc"
    # - sudo podman exec -it $CONTAINER_NAME bash -c "cd /data/android-ndk-r27b && ./build/tools/make_standalone_toolchain.py --arch arm64 --api 30 --install-dir /data/android-ndk-r27b"
    - sleep 1
    - sudo podman exec -it $CONTAINER_NAME bash -c -i "cd /code && cmake -DCMAKE_TOOLCHAIN_FILE=/data/android-ndk-r27b/build/cmake/android.toolchain.cmake -DANDROID_ABI=arm64-v8a -DANDROID_PLATFORM=android-34 -DCMAKE_BUILD_TYPE=RelWithDebInfo -DBUILD_SHARED_LIBS=OFF -DGGML_OPENMP=OFF -DSMART_ENABLE_ASAN=OFF -DSMART_WITH_QNN=ON -S . -B build_android"
    - sudo podman exec -it $CONTAINER_NAME bash -c -i "cd /code && cmake --build build_android --config RelWithDebInfo --parallel 12"
    - sudo podman exec -it $CONTAINER_NAME bash -c -i "cp -r /code/build_android /data"

deploy:
  stage: deploy
  script:
    - echo "Deploying binaries and models to your Android device."
    - sleep 2
    - adb push /home/gitlab-runner/Downloads/build_android/bin/run /data/local/tmp/
    - adb push /home/gitlab-runner/Downloads/build_android/tools/gguf_config_to_json/config_generator /data/local/tmp/config_generator
    - sleep 2
    - adb shell "ls -ahl /data/local/tmp/run"
    - scp -P 8022 -r ~/Downloads/build_android/bin/run u0_a334@192.168.61.65:/data/data/com.termux/files/home

test_llama3.1:
  stage: test
  before_script:
    - pwd .
    - echo "$CI_PROJECT_DIR"
    - sudo chmod -R 777 .
  script:
    - adb shell "/data/local/tmp/config_generator --file-path /data/local/tmp/llama_3.1_8b_q4_0.gguf --target-path /data/local/tmp/llama3.1.json"
    - adb shell "/data/local/tmp/run --file-path /data/local/tmp/llama_3.1_8b_q4_0.gguf --vocab-path /data/local/tmp/llama_3.1_8b_vocab.gguf --prompt \"One day,\" --steps 32 --config-path /data/local/tmp/llama3.1.json"

# test_phi3:
#   stage: test
#   script:
#     - adb shell "/data/local/tmp/run --file-path /data/local/tmp/phi3_mini_4k_instruct_q4_0.gguf --vocab-path /data/local/tmp/phi3_mini_4k_instruct_vocab.gguf --prompt \"One day,\" --steps 64"

# test_sparse:
#   stage: test
#   script:
#     - adb shell "/data/local/tmp/config_generator --file-path /data/local/tmp/llama_3.2_1b_q4_0.gguf --target-path /data/local/tmp/llama3.2.json"
#     - adb shell "/data/local/tmp/run --file-path /data/local/tmp/llama_3.2_1b_q4_0.gguf --vocab-path /data/local/tmp/llama_3.2_1b_vocab.gguf --prompt \"One day,\" --steps 32 --attn-type quest --config-path /data/local/tmp/llama3.2.json"

test_thread:
  stage: test
  script:
    - adb shell "/data/local/tmp/config_generator --file-path /data/local/tmp/llama_3.2_1b_q4_0.gguf --target-path /data/local/tmp/llama3.2.json"
    - adb shell "/data/local/tmp/run --file-path /data/local/tmp/llama_3.2_1b_q4_0.gguf --vocab-path /data/local/tmp/llama_3.2_1b_vocab.gguf --prompt \"One day,\" --steps 32 --n-threads 8 --config-path /data/local/tmp/llama3.2.json"

# test_long_out:
#   stage: test
#   script:
#     - adb shell "/data/local/tmp/run --file-path /data/local/tmp/phi3_mini_4k_instruct_q4_0.gguf --vocab-path /data/local/tmp/phi3_mini_4k_instruct_vocab.gguf --prompt \"One day,\" --steps 4096"

test_qnn:
  when: manual
  stage: test
  script:
    - ./.gitlab/deploy_to_remote_phone.sh
